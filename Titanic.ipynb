{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  891\n",
      "\n",
      "Sample Record:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass                     Name   Sex   Age  SibSp  \\\n",
       "0            1         0       3  Braund, Mr. Owen Harris  male  22.0      1   \n",
       "\n",
       "   Parch     Ticket  Fare Cabin Embarked  \n",
       "0      0  A/5 21171  7.25   NaN        S  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\ggiorcelli\\\\Downloads\\\\train.csv')\n",
    "print(\"Number of records: \",len(df))\n",
    "print(\"\\nSample Record:\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data types:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing records\n",
    "print(\"Value Counts: \")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ticket and cabin are irrelevant and with a lot of Nas so I'll drop them\n",
    "df.drop(['Ticket','Cabin'],axis=1, inplace=True)\n",
    "#Passenger id and name are also irrelevant\n",
    "df.drop(['PassengerId','Name'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    891\n",
       "Pclass      891\n",
       "Sex         891\n",
       "Age         714\n",
       "SibSp       891\n",
       "Parch       891\n",
       "Fare        891\n",
       "Embarked    889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It looks like Age has a few NAs. I'll replace the missing values with the mean age for the corresponding class and gender\n",
    "df.Age = df.Age.fillna(-1)\n",
    "df1 = df.replace(-1, df.groupby(['Sex','Pclass'], as_index=False)['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>19.055965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>19.055965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.940789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0          0       3    male  22.000000      1      0   7.2500        S\n",
       "1          1       1  female  38.000000      1      0  71.2833        C\n",
       "2          1       3  female  26.000000      0      0   7.9250        S\n",
       "3          1       1  female  35.000000      1      0  53.1000        S\n",
       "4          0       3    male  35.000000      0      0   8.0500        S\n",
       "5          0       3    male  19.055965      0      0   8.4583        Q\n",
       "6          0       1    male  54.000000      0      0  51.8625        S\n",
       "7          0       3    male   2.000000      3      1  21.0750        S\n",
       "8          1       3  female  27.000000      0      2  11.1333        S\n",
       "9          1       2  female  14.000000      1      0  30.0708        C\n",
       "10         1       3  female   4.000000      1      1  16.7000        S\n",
       "11         1       1  female  58.000000      0      0  26.5500        S\n",
       "12         0       3    male  20.000000      0      0   8.0500        S\n",
       "13         0       3    male  39.000000      1      5  31.2750        S\n",
       "14         0       3  female  14.000000      0      0   7.8542        S\n",
       "15         1       2  female  55.000000      0      0  16.0000        S\n",
       "16         0       3    male   2.000000      4      1  29.1250        Q\n",
       "17         1       2    male  19.055965      0      0  13.0000        S\n",
       "18         0       3  female  31.000000      1      0  18.0000        S\n",
       "19         1       3  female  27.940789      0      0   7.2250        C"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived    889\n",
       "Pclass      889\n",
       "Sex         889\n",
       "Age         889\n",
       "SibSp       889\n",
       "Parch       889\n",
       "Fare        889\n",
       "Embarked    889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Two people did not embark so I'll remove their records from the data\n",
    "df1 = df1.dropna()\n",
    "\n",
    "print(\"Value Counts:\")\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate by class and sex\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAE3CAYAAABRmAGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAYZ7pLUIMNdkhpkuEtSg/4/RDwjkx9SW4sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a55e553358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate by age bucket\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEnCAYAAABSTgMJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGFRJREFUeJzt3XuwXWd53/HvD9niUsrVasxYMnKICZgCAQtREtIYEk/k\nuEFcDMghEEIY43SUTKYlg+i0aWeYULu0MwnEjsahDhAY3LQEULGMSQiXpoZE8iUOdjARxmA5UITN\n3SRG+Okfe0neOj7y2efsvaS93vP9zJzx3mu9+q1H2zrPWefda683VYUkqS0POt4FSJJmz+YuSQ2y\nuUtSg2zuktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDXohON14JNOOqk2btx4vA4vSYN07bXXfq2q\n1i017rg1940bN7J3797jdXhJGqQkX5xknNMyktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDVoouae\nZEuSW5LsS7Jjkf2/meSG7uszSX6Q5DGzL1eSNIklm3uSNcAlwDnAGcD5Sc4YH1NVb6mqH6uqHwPe\nCHyiqu7qo2BJ0tIm+RDTZmBfVd0KkOQKYCtw81HGnw+8d6UFbdxx5cRjb7vo3JUeRpKaNsm0zCnA\n7WPP93fb7ifJw4AtwPumL02StFKzfkP154H/e7QpmSQXJNmbZO+BAwdmfGhJ0iGTNPc7gA1jz9d3\n2xazjQeYkqmqy6pqU1VtWrduyfveSJJWaJLmvgc4PclpSdYyauC7Fg5K8kjgp4APzrZESdJyLfmG\nalUdTLIduBpYA1xeVTclubDbv7Mb+iLgI1X13d6qlSRNZKJb/lbVbmD3gm07Fzx/B/COWRUmSVo5\nP6EqSQ2yuUtSg2zuktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDXI5i5JDbK5S1KDbO6S1CCbuyQ1\nyOYuSQ2yuUtSg2zuktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDXI5i5JDZqouSfZkuSWJPuS7DjK\nmLOS3JDkpiSfmG2ZkqTlOGGpAUnWAJcAZwP7gT1JdlXVzWNjHgVcCmypqi8l+Wd9FSxJWtokZ+6b\ngX1VdWtV3QNcAWxdMOYXgD+pqi8BVNVXZ1umJGk5JmnupwC3jz3f320b90Tg0Uk+nuTaJK9aLCjJ\nBUn2Jtl74MCBlVUsSVrSrN5QPQE4EzgX+FngPyR54sJBVXVZVW2qqk3r1q2b0aElSQstOecO3AFs\nGHu+vts2bj9wZ1V9F/hukk8CTwc+N5MqJUnLMsmZ+x7g9CSnJVkLbAN2LRjzQeC5SU5I8jDg2cDf\nzrZUSdKkljxzr6qDSbYDVwNrgMur6qYkF3b7d1bV3yb5MHAjcC/w9qr6TJ+FS5KObpJpGapqN7B7\nwbadC56/BXjL7EqTJK3URM1dR7dxx5XLGn/bRef2VIkk3cfbD0hSg2zuktQgm7skNcjmLkkNsrlL\nUoNs7pLUIJu7JDXI5i5JDbK5S1KDbO6S1CCbuyQ1yOYuSQ2yuUtSg2zuktQgm7skNcjmLkkNsrlL\nUoNs7pLUIJu7JDVoouaeZEuSW5LsS7Jjkf1nJflmkhu6r9+afamSpEktuUB2kjXAJcDZwH5gT5Jd\nVXXzgqH/p6r+VQ81SpKWaZIz983Avqq6taruAa4AtvZbliRpGpM091OA28ee7++2LfTjSW5MclWS\npywWlOSCJHuT7D1w4MAKypUkTWJWb6heB5xaVU8D3gZ8YLFBVXVZVW2qqk3r1q2b0aElSQtN0tzv\nADaMPV/fbTusqr5VVd/pHu8GTkxy0syqlCQtyyTNfQ9wepLTkqwFtgG7xgckOTlJusebu9w7Z12s\nJGkyS14tU1UHk2wHrgbWAJdX1U1JLuz27wTOA341yUHge8C2qqoe65YkPYAlmzscnmrZvWDbzrHH\nvwf83mxLkyStlJ9QlaQG2dwlqUE2d0lqkM1dkhpkc5ekBtncJalBNndJapDNXZIaZHOXpAbZ3CWp\nQTZ3SWqQzV2SGmRzl6QG2dwlqUE2d0lqkM1dkhpkc5ekBtncJalBNndJatBEa6hKat/GHVdOPPa2\ni87tsRLNgmfuktSgic7ck2wBfhdYA7y9qi46yrhnAZ8CtlXV/5pZlVJPhni2OsSadewteeaeZA1w\nCXAOcAZwfpIzjjLuYuAjsy5SkrQ8k0zLbAb2VdWtVXUPcAWwdZFxvwa8D/jqDOuTJK3AJM39FOD2\nsef7u22HJTkFeBHw+w8UlOSCJHuT7D1w4MBya5UkTWhWV8v8DvCGqro3yVEHVdVlwGUAmzZtqhkd\nW6uA88zS8kzS3O8ANow9X99tG7cJuKJr7CcBP5fkYFV9YCZVSpKWZZLmvgc4PclpjJr6NuAXxgdU\n1WmHHid5B/AhG7sk8Leu42XJ5l5VB5NsB65mdCnk5VV1U5ILu/07e65RkrRME825V9VuYPeCbYs2\n9ap69fRlSZKm4SdUJalBNndJapDNXZIaZHOXpAbZ3CWpQd7PXTOznOuZoe1rmr22W8ebZ+6S1CCb\nuyQ1aNVMy/hrsqTVxDN3SWrQqjlz1338LUZqn2fuktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDXI\nSyHnmJcsSlopz9wlqUE2d0lq0ETNPcmWJLck2ZdkxyL7tya5MckNSfYmee7sS5UkTWrJOfcka4BL\ngLOB/cCeJLuq6uaxYR8FdlVVJXka8MfAk/ooWJK0tEnO3DcD+6rq1qq6B7gC2Do+oKq+U1XVPf0n\nQCFJOm4mae6nALePPd/fbTtCkhcl+SxwJfCaxYKSXNBN2+w9cODASuqVJE1gZm+oVtX7q+pJwAuB\nNx1lzGVVtamqNq1bt25Wh5YkLTBJc78D2DD2fH23bVFV9Ungh5OcNGVtkqQVmqS57wFOT3JakrXA\nNmDX+IAkP5Ik3eNnAg8G7px1sZKkySx5tUxVHUyyHbgaWANcXlU3Jbmw278TeAnwqiTfB74HvHzs\nDVZJ0jE20e0Hqmo3sHvBtp1jjy8GLp5taZKklfITqpLUIJu7JDXI5i5JDbK5S1KDbO6S1CCbuyQ1\nyOYuSQ2yuUtSg2zuktQgm7skNcjmLkkNsrlLUoNs7pLUIJu7JDVoolv+StI82rjjyonH3nbRuT1W\nMn88c5ekBtncJalBNndJapDNXZIaZHOXpAZN1NyTbElyS5J9SXYssv8VSW5M8jdJrkny9NmXKkma\n1JLNPcka4BLgHOAM4PwkZywY9gXgp6rqqcCbgMtmXagkaXKTnLlvBvZV1a1VdQ9wBbB1fEBVXVNV\nX++efhpYP9syJUnLMUlzPwW4fez5/m7b0fwKcNU0RUmSpjPTT6gmeR6j5v7co+y/ALgA4NRTT53l\noSVJYyY5c78D2DD2fH237QhJnga8HdhaVXcuFlRVl1XVpqratG7dupXUK0mawCTNfQ9wepLTkqwF\ntgG7xgckORX4E+CVVfW52ZcpSVqOJadlqupgku3A1cAa4PKquinJhd3+ncBvAY8FLk0CcLCqNvVX\ntiTpgUw0515Vu4HdC7btHHv8WuC1sy1NkrRSfkJVkhpkc5ekBtncJalBNndJapDNXZIaZHOXpAbZ\n3CWpQTZ3SWqQzV2SGmRzl6QG2dwlqUE2d0lqkM1dkhpkc5ekBtncJalBNndJapDNXZIaZHOXpAbZ\n3CWpQTZ3SWqQzV2SGjRRc0+yJcktSfYl2bHI/icl+VSSf0zy+tmXKUlajhOWGpBkDXAJcDawH9iT\nZFdV3Tw27C7g14EX9lKlJGlZJjlz3wzsq6pbq+oe4Apg6/iAqvpqVe0Bvt9DjZKkZZqkuZ8C3D72\nfH+3bdmSXJBkb5K9Bw4cWEmEJGkCx/QN1aq6rKo2VdWmdevWHctDS9KqMklzvwPYMPZ8fbdNkjSn\nJmnue4DTk5yWZC2wDdjVb1mSpGksebVMVR1Msh24GlgDXF5VNyW5sNu/M8nJwF7gEcC9SX4DOKOq\nvtVj7ZKko1iyuQNU1W5g94JtO8cef4XRdI0kaQ74CVVJapDNXZIaZHOXpAbZ3CWpQTZ3SWqQzV2S\nGmRzl6QG2dwlqUE2d0lqkM1dkhpkc5ekBtncJalBNndJapDNXZIaZHOXpAbZ3CWpQTZ3SWqQzV2S\nGmRzl6QG2dwlqUETNfckW5LckmRfkh2L7E+St3b7b0zyzNmXKkma1JLNPcka4BLgHOAM4PwkZywY\ndg5wevd1AfD7M65TkrQMk5y5bwb2VdWtVXUPcAWwdcGYrcC7auTTwKOSPG7GtUqSJpSqeuAByXnA\nlqp6bff8lcCzq2r72JgPARdV1V90zz8KvKGq9i7IuoDRmT3AjwK3TFjnScDXJhy7XH1lDy23z+yh\n5faZPbTcPrOHlttn9nJyH19V65YadMJ09SxPVV0GXLbcP5dkb1Vt6qGk3rKHlttn9tBy+8weWm6f\n2UPL7TO7j9xJpmXuADaMPV/fbVvuGEnSMTJJc98DnJ7ktCRrgW3ArgVjdgGv6q6a+RfAN6vqyzOu\nVZI0oSWnZarqYJLtwNXAGuDyqropyYXd/p3AbuDngH3A3cAvz7jOZU/lzEH20HL7zB5abp/ZQ8vt\nM3touX1mzzx3yTdUJUnD4ydUJalBNndJapDNXZIadEyvcz/ekrx4gmH/UFW7ey9Gkno0d2+oJvnW\nUkOAL1fVE1eQfSfwwS7jaP5lVT1hmbkLLw1dzF1V9ep5yO0ze2i5fWab23/20HL7zh43j2fun6+q\nZzzQgCTXrzD7qqp6zRLZ715B7pOB1z5QLKObr81Lbp/ZQ8vtM9vc/rOHltt39n2qaq6+gB+exZhj\nXPPLZjHmWOUOsWZfi+HmDrHmIb4WC7/mblqmb0keCWwBTuk23QFcXVXfOH5VSdJszd3VMkleM/Z4\nfZKPJvlGkmuSLHuefUH2q4DrgLOAh3VfzwOu7fatNPdpY49PTPLvk+xK8uYkD5si94Qkr0vy4W4R\nlBuTXJXkwiQnrjR3iDX3Ve8Qax5avUOseYjfe/c7zryduSe5rqqe2T3+Y+DPgLczumf89qr66Smy\nb2F0u+JvLNj+aOAvawVv0i5S838DHgv8IfBC4LFVtaIfHEneC3wDeCewv9u8Hvgl4DFV9fKV5A6x\n5r7qHWLNQ6t3iDUP8Xvvfqad15n1F3Dd2OO/XrDv+imzPwc8cpHtjwT+borc68ce3wCc2D0OcOM0\n9a5kX4s191XvEGseWr1DrHmI33sLv+bxapn1Sd7K6C96UpITq+r73b6pfh0Cfhu4LslHgNu7bacC\nZwNvmiL3kUlexGia66GH6q2qSjLNr0Z3JXkp8L6quhcgyYOAlwJfnyJ3iDX3Ve8Qax5avUOseYjf\ne0eYx+b+m2OP9wIPB76e5GTuf6vhZamqd2Z0jenPct8bqh8H3lhV0/wP+wTwgu7xNUl+qKr+X1fz\nNKu2bAMuBi5Ncqi+RwEf6/ZN41jVHEa/GU1bc1/1wuKv86OBP2c+a27hNQ6jf8tDeY1h/r/3jjB3\nc+5aXJLHAlTVnce7lklZc/+GVi8Mr+ah1XvI3F0tc7wk+Zuecs+e8s8/IskTqurO8X9c4++4T5u9\nyPapspOcnOTkrt4HJXlxkqdMkzme2z1eN6vccYde5yRvnmXuIbPO7V7jR3SvxZNmmZ3RAj0zyU1y\napKHdE/vAl6Q5G1JfjXJimcQxnMz8sszyn1BkgfDff8mVpr1QNl9WlVn7jn6vWUC7KwJFp1dwTG/\nVFWnrvDPvgz4HeCrjN5veHVV7en2HX7HfZ6yk7wO2MHoNb0YeDXwGeC5wH+pqv8+T7ld9lsXbgJe\nCbwLoKp+fc5yP1BVL+web2X0//HjwE8Ab66qd8w498eB/7zS3C7vM8Dmqro7ycXAE4APAM8HqCU+\nOX4ccr8HfBe4Cngvo8/C/GAlWccye9w8zrn36X8A7wEW+4n2kEW2TSRHv1dEGF3mtFL/Djizqr6c\nZDPwR0neWFXv77Kn0Vf2duApwEOBLwI/UlVfyehy048BK23CfeUCvIjRPOhHuO/vvg24dorMPnMf\nP/b4DcDzq+oLSU4CPgq8Y85yAR5UVXd3j38GeFb3RuW7k/z1HOZ+ltEPiPOAfwv8YZL3A++tqk9M\nkdt39mGDae7dmcRXquovp4i5EfivVfWZRfJ/ZorcnwR+EfjOwlhg8xS5a6pbi7aq/irJ84APJdnA\n4j+g5iH7+903291JPl9VX+mO8fUprwToKxfgDEZXS20BXl9Vf5/kP1bVO+c0d/zvu7aqvgBQVV9L\ncu8c5gLcnuT5VfXnwG3ABuCLh+az5zC3uoss/gD4g2468GXARUnWV9WGOc0+4iiD+ALeDPxvRjf/\nWmnGTwKnHmXfpilyrwKed5R9n5wi9xrgCQu2/VNGZ1H/OOXr2Us2o7PSQ9ftrh/b/hAWfG5hHnIX\nHONMRr8FvB64bRaZfeQCPwC+BXwbuAd4XLd9LdNd291LbpexoXsNPtl9H3+9e3498NNzmHvUz9QA\nj5/ytegte/xrVc25D02SpwPfrap9C7afyOjGQu+Zt+wkpwJ/X1UHF2w/BXhyVf3ZPOUucpwA/xp4\nTlX94iwy+8xdcIxHMXotPjWvuUmeDDyR0azBfmBPddeRz1NukrOq6uPT1nWss484zjw293hzL0ma\nytxdCpmebu4lSavJ3J25p6ebe0nSajJ3Z+6MrjBZ7CfOvUx/+d/iB0y2Jnl2H9mSdDzM46WQfd3c\n64E8G3hqkhOq6pxZhSZ5J3A3cEktcvnlvOX2mT203D6zze0/e2i5fWTP3bQMHJ6CGb+516E3VKe9\nG9sxleRZjH4wba6qN8x7bp/ZQ8vtM9vc/rOHlttH9tw19ySpJYqaZMyExzoNeAZwc1V9dto8SZoX\n8zjn/rEkv9Zd13xYkrVJnt/96vJLKwlO8oGxx1sZ3W7054FdSV690oIzsCXEhlhzX/UOseah1TvE\nmof4vXe/48zhmftDgNcArwBOY7TU1UMZ/SD6CHBpVV2/wuzrq+oZ3eNrgFfU2L0zqurpK8wd1BJi\nQ6y5r3qHWPPQ6h1izUP83rufWX3UtY8vRncrfBzwqBnljS/ht3fBvhUv4cfAlhAbYs191TvEmodW\n7xBrHuL33sKveZyWOayqvl9VX67ZfTL16Um+leTbwNOSPA5GUz7Amily70ry0oyW4aLLfFCSlzOD\nJcSSvIQFy3Ex/Y3DhlZzX/XC8GoeWr0wvJqH+L13hHm8FLI3VXW0Bv4w4HVTRPe1JNexXlpunmvu\na2k5OLZLta3G5fvg2NY8z8v3Qb9L+B02d3PufUr6vxInA1ySa2g1D61eGF7NQ6sXrHmhuZ6W6UFv\nV+IcUvdfDm+qZfaOZha56WkJvwxs+b7x7O7xzJfwK5fvO0JmtIRfBrZ8X5fX2xJ+RxxnlZ25L3Yl\nzkMYzbdPdSXOAxxzxcvs9Zmb/pbZG9TyfX1mx+X7Jsmeagm/DGz5vi7bZfZmrar+AbiU0VzXicBJ\nwPemfcM2PS2z11dup69l9oa2fF+f2S7f13/20JbvA5fZ61f37veXZxTX1zJ7feVCf8vsDW35vj6z\nXb6v/+yhLd8Hx2iZvVXb3Gfs08Ddi/3UzegWxvOWC/Dtbr798wDdmfZZjH71nGauua/cSnJi90P5\n3EMbu6m2ad876iW7qr4N/EaSM4H3JLlyBrX2lkt3qTCjk4cHJ3lc9/9v2kuF+8x+LfCuJP8J+CZw\nQ5IbGF198m/mMBcW/AbbnUy8FXhrkscv/kdWcJDVNOeu+2S0zN7dVfV3C7ZPu8xeX7m9LbPXZ/ZY\nlsv39ZidgSzf12WeVat1mb2hSfq5xLKv3D6zh5bbZ7a5/WcPLbfv7HGr7VLIvvR1iWWfl24OrWZf\ni+HmDrHmIb4WR/DMfQbS0yWWfeUOseaGXoupb4J3jHOH+BrPbW7f2Uccx+Y+W5nhJZbHIrfP7KHl\n9pltbv/ZQ8vtPdvmLkntcc5dkhpkc5ekBtnctSoleWGSSg83xZLmgc1dq9X5wF90/5WaY3PXqpPk\n4Yzu+PgrdIsjZLQSzqVJPpvkT5PsTnJet+/MJJ9Icm2Sq9Ot4CXNM5u7VqOtwIer6nPAnRndo+XF\nwEZGN+V6JfAcOHyp2tuA86rqTOBy4LePR9HScnjjMK1G5wO/2z2+ont+AvA/u/uGfCXJx7r9Pwr8\nc+BPk8Dogyazupuo1Bubu1aVJI9hdC/tp2Z0O981jG5H+/6j/RHgpqp6zjEqUZoJp2W02pwH/FFV\nPb6qNnb3zv4CoyXaXtLNvf8QcFY3/hZgXZLD0zSZ4fJ7Ul9s7lptzuf+Z+nvA05mdEvXm4F3A9cB\n36yqexj9QLg4oxV4bmC0NJw017z9gNRJ8vCq+k5Gq+38FfAT3UIK0uA45y7d50MZLR6xFniTjV1D\n5pm7JDXIOXdJapDNXZIaZHOXpAbZ3CWpQTZ3SWrQ/we+nKLB1yKDFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a55f647d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Quick exploratory analysis on survivial rate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Survival rate by class and sex\")\n",
    "(df1.groupby(['Pclass','Sex'])['Survived'].mean()).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "print(\"Survival rate by age bucket\")\n",
    "(df1.groupby(pd.cut(df1[\"Age\"], np.arange(0, df1.Age.max(), 5)))['Survived'].mean()).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating dummy variables for sex and embarked\n",
    "df1 = pd.get_dummies(data=df1, columns=['Sex','Embarked','Pclass'])\n",
    "\n",
    "#dropping male flag\n",
    "df1.drop(\"Sex_male\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>19.055965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>19.055965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>27.940789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived        Age  SibSp  Parch     Fare  Sex_female  Embarked_C  \\\n",
       "0          0  22.000000      1      0   7.2500           0           0   \n",
       "1          1  38.000000      1      0  71.2833           1           1   \n",
       "2          1  26.000000      0      0   7.9250           1           0   \n",
       "3          1  35.000000      1      0  53.1000           1           0   \n",
       "4          0  35.000000      0      0   8.0500           0           0   \n",
       "5          0  19.055965      0      0   8.4583           0           0   \n",
       "6          0  54.000000      0      0  51.8625           0           0   \n",
       "7          0   2.000000      3      1  21.0750           0           0   \n",
       "8          1  27.000000      0      2  11.1333           1           0   \n",
       "9          1  14.000000      1      0  30.0708           1           1   \n",
       "10         1   4.000000      1      1  16.7000           1           0   \n",
       "11         1  58.000000      0      0  26.5500           1           0   \n",
       "12         0  20.000000      0      0   8.0500           0           0   \n",
       "13         0  39.000000      1      5  31.2750           0           0   \n",
       "14         0  14.000000      0      0   7.8542           1           0   \n",
       "15         1  55.000000      0      0  16.0000           1           0   \n",
       "16         0   2.000000      4      1  29.1250           0           0   \n",
       "17         1  19.055965      0      0  13.0000           0           0   \n",
       "18         0  31.000000      1      0  18.0000           1           0   \n",
       "19         1  27.940789      0      0   7.2250           1           1   \n",
       "\n",
       "    Embarked_Q  Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "0            0           1         0         0         1  \n",
       "1            0           0         1         0         0  \n",
       "2            0           1         0         0         1  \n",
       "3            0           1         1         0         0  \n",
       "4            0           1         0         0         1  \n",
       "5            1           0         0         0         1  \n",
       "6            0           1         1         0         0  \n",
       "7            0           1         0         0         1  \n",
       "8            0           1         0         0         1  \n",
       "9            0           0         0         1         0  \n",
       "10           0           1         0         0         1  \n",
       "11           0           1         1         0         0  \n",
       "12           0           1         0         0         1  \n",
       "13           0           1         0         0         1  \n",
       "14           0           1         0         0         1  \n",
       "15           0           1         0         1         0  \n",
       "16           1           0         0         0         1  \n",
       "17           0           1         0         1         0  \n",
       "18           0           1         0         0         1  \n",
       "19           0           0         0         0         1  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(20)  #Train set looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      False\n",
       "Age           False\n",
       "SibSp         False\n",
       "Parch         False\n",
       "Fare          False\n",
       "Sex_female    False\n",
       "Embarked_C    False\n",
       "Embarked_Q    False\n",
       "Embarked_S    False\n",
       "Pclass_1      False\n",
       "Pclass_2      False\n",
       "Pclass_3      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for NAs\n",
    "np.isnan(df1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing and preparing test dataset\n",
    "test_df = pd.read_csv('C:\\\\Users\\\\ggiorcelli\\\\Downloads\\\\train.csv')\n",
    "test_df.drop(['Ticket','Cabin','PassengerId','Name'],axis=1, inplace=True)\n",
    "\n",
    "#Note: I'm replacing missing age with mean age for corresponding class and sex from train dataset to ensure normalization\n",
    "test_df.Age = test_df.Age.fillna(-1)\n",
    "test_df1 = test_df.replace(-1, df.groupby(['Sex','Pclass'], as_index=False)['Age'].mean())\n",
    "\n",
    "#Create dummies and drop male flag\n",
    "test_df1 = pd.get_dummies(data=test_df1, columns=['Sex','Embarked','Pclass'])\n",
    "test_df1.drop('Sex_male',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Renaming test and train for easier coding\n",
    "train_x, train_y = df1.iloc[:,1:], df1.iloc[:,0]\n",
    "test_x, test_y = test_df1.iloc[:,1:], test_df1.iloc[:,0]\n",
    "\n",
    "#Library import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train:  0.804274465692\n",
      "accuracy on test:  0.804713804714\n",
      "recall:  0.701754385965\n",
      "\n",
      "Confusion matrix\n",
      "[[477  72]\n",
      " [102 240]]\n",
      "\n",
      "      variable               coeff   p_val\n",
      "4   Sex_female     [2.59635168667]  0.0000\n",
      "8     Pclass_1     [0.94105921114]  0.0000\n",
      "5   Embarked_C    [0.173526489211]  0.0000\n",
      "3         Fare  [0.00267104603955]  0.0000\n",
      "0          Age  [-0.0342128269295]  0.0000\n",
      "2        Parch  [-0.0793257414616]  0.0012\n",
      "10    Pclass_3     [-1.0636214137]  0.0000\n"
     ]
    }
   ],
   "source": [
    "#Create model\n",
    "model = LogisticRegression()\n",
    "model = model.fit(train_x, train_y)\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "#Calculating chi2 to get pvalues\n",
    "scores, pvalues = chi2(train_x, train_y) \n",
    "pvalues=[\"{0:.4f}\".format(x)for x in pvalues] \n",
    "\n",
    "p_val = pd.DataFrame(list(zip(train_x.columns, np.transpose(model.coef_),  np.transpose(pvalues))) ,columns=['variable','coeff','p_val']).sort_values(by='p_val',ascending=True)\n",
    "p_val['p_val'] = p_val['p_val'].astype(float)\n",
    "\n",
    "#Check the accuracy on the training and test set\n",
    "print(\"accuracy on train: \", model.score(train_x, train_y))\n",
    "print(\"accuracy on test: \",  model.score(test_x, test_y))\n",
    "print(\"recall: \",recall_score(test_y, yhat))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(test_y, yhat))\n",
    "print(\"\")\n",
    "print(p_val.loc[p_val['p_val'] < 0.01].sort_values(by='coeff',ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train:  0.805399325084\n",
      "accuracy on test:  0.805836139169\n",
      "recall:  0.704678362573\n",
      "\n",
      "Confusion matrix\n",
      "[[477  72]\n",
      " [101 241]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now let's see if we can improve the accuracy by normalizing age and fare\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(train_x[['Age','Fare']])\n",
    "train_x[['Age','Fare']] = scaler.transform(train_x[['Age','Fare']])\n",
    "test_x[['Age','Fare']] = scaler.transform(test_x[['Age','Fare']])\n",
    "\n",
    "#Create model with standardized variables\n",
    "model = LogisticRegression()\n",
    "model = model.fit(train_x, train_y)\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "#Check the accuracy on the training and test set\n",
    "print(\"accuracy on train: \", model.score(train_x, train_y))\n",
    "print(\"accuracy on test: \",  model.score(test_x, test_y))\n",
    "print(\"recall: \",recall_score(test_y, yhat))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(test_y, yhat))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train:  0.81214848144\n",
      "accuracy on test:  0.812570145903\n",
      "recall:  0.710526315789\n",
      "\n",
      "Confusion matrix\n",
      "[[481  68]\n",
      " [ 99 243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Small but noticeable improvement in performance using the standard scaler\n",
    "#Now I'll try one more technique: log transformation\n",
    "\n",
    "train_x.Age, train_x.Fare = np.log(train_x.Age.loc[train_x.Age != 0]), np.log(train_x.Fare.loc[train_x.Fare != 0])\n",
    "test_x.Age, test_x.Fare = np.log(test_x.Age.loc[test_x.Age != 0]), np.log(test_x.Fare.loc[test_x.Fare != 0])\n",
    "\n",
    "#One record throws an NA after log transformation so I'll replace it it with the column mean\n",
    "train_x.Fare = train_x.Fare.fillna(train_x.Fare.mean())\n",
    "test_x.Fare = test_x.Fare.fillna(test_x.Fare.mean())\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(train_x, train_y)\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "#Check the accuracy on the training and test set\n",
    "print(\"accuracy on train: \", model.score(train_x, train_y))\n",
    "print(\"accuracy on test: \",  model.score(test_x, test_y))\n",
    "print(\"recall: \",recall_score(test_y, yhat))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(test_y, yhat))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Conclusion: the best normalization technique for modeling is the one with log normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "ROC Score:  0.863835362541\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLipPFM4556LyROGccy6q/wdGw+KUS1K8WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a5602d2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculate and plot ROC\n",
    "phat = model.predict_proba(test_x)[:,1]\n",
    "print(\"\\n-----------------------------\")\n",
    "print(\"ROC Score: \",metrics.roc_auc_score(test_y, phat))\n",
    "print(\"-----------------------------\\n\")\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(test_y, phat)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#Plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.88      0.85       549\n",
      "          1       0.78      0.71      0.74       342\n",
      "\n",
      "avg / total       0.81      0.81      0.81       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report\\n\")\n",
    "print(classification_report(test_y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now that we have proven that log-transforming the data is the optimal data processing method /\n",
    "## we'll feed the data to a stroger alogorithm. General domain knowledge tells us that tree-based models / \n",
    "## are usually the best models for binary classification. Hence, once we import the data into Weka and Orange for /\n",
    "## the modeling part of this project, we will probably use a tree based model.\n",
    "## Before doing so, let's see how a basic extreme gradient boosting alorithm performs on the data and let's /\n",
    "## see if there's is more room for improvement before taking the data into Weka or Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ggiorcelli\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-5.3.0-posix-seh-rt_v4-rev0\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train:  0.985376827897\n",
      "accuracy on test:  0.985409652076\n",
      "recall:  0.973684210526\n",
      "\n",
      "Confusion matrix\n",
      "[[545   4]\n",
      " [  9 333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "model = xgb.XGBClassifier(scale_pos_weight=1, n_estimators=10000, learning_rate=0.1)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "#Check the accuracy on the training and test set\n",
    "print(\"accuracy on train: \", model.score(train_x, train_y))\n",
    "print(\"accuracy on test: \",  model.score(test_x, test_y))\n",
    "print(\"recall: \",recall_score(test_y, yhat))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(test_y, yhat))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       549\n",
      "          1       0.99      0.97      0.98       342\n",
      "\n",
      "avg / total       0.99      0.99      0.99       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\\n\")\n",
    "print(classification_report(test_y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## As expected, a tree-base model (XGboost in this case) performs much better than logistic regression. \n",
    "## This proves our hypotesis, we will use a tree based model for the modeling part\n",
    "\n",
    "## Before exporting the data we have one last thing left to try.\n",
    "## Let's see if clustering the data before fitting the model improves our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Our dataset is a mix of continuous and boolean variables so we will need to use an algorithm that / \n",
    "## tollerate such datset. DBscan is a density-based clustering algorithm that works well with data of mixed types\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "clust = DBSCAN(eps=0.8, min_samples=20).fit(train_x)\n",
    "\n",
    "train_x['Cluster'] = clust.labels_\n",
    "test_x['Cluster'] = clust.fit_predict(test_x)\n",
    "\n",
    "train_x = pd.get_dummies(data=train_x, columns=['Cluster'])\n",
    "test_x = pd.get_dummies(data=test_x, columns=['Cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train:  0.985376827897\n",
      "accuracy on test:  0.985409652076\n",
      "recall:  0.988304093567\n",
      "\n",
      "Confusion matrix\n",
      "[[540   9]\n",
      " [  4 338]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(scale_pos_weight=1.0, n_estimators=9000, learning_rate=0.1)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "yhat = model.predict(test_x)\n",
    "\n",
    "#Check the accuracy on the training and test set\n",
    "print(\"accuracy on train: \", model.score(train_x, train_y))\n",
    "print(\"accuracy on test: \",  model.score(test_x, test_y))\n",
    "print(\"recall: \",recall_score(test_y, yhat))\n",
    "print(\"\")\n",
    "print(\"Confusion matrix\")\n",
    "print(metrics.confusion_matrix(test_y, yhat))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       549\n",
      "          1       0.97      0.99      0.98       342\n",
      "\n",
      "avg / total       0.99      0.99      0.99       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\\n\")\n",
    "print(classification_report(test_y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## We can see how recall increased but precision decreased proportionally and the f1 score remained the same. This tells us  / \n",
    "##that clustering the data does not improve the model's performance. We will not include clustering in the modeling portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Exporting log-transformed data into a csv file for modeling in Weka\n",
    "\n",
    "train_x['Survived'] = train_y.copy()\n",
    "test_x['Survived'] = test_y.copy()\n",
    "\n",
    "processed_df = train_x.append(test_x)\n",
    "processed_df.to_csv('processed_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
